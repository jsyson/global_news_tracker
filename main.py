import streamlit as st
import logging
import requests
from bs4 import BeautifulSoup
import pickle
import config


# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.DEBUG)


# # # # # # # # # # # # # # # # # # # #
# íšŒì‚¬ ëª©ë¡ ë°›ì•„ì˜¤ê¸° (skip)
# # # # # # # # # # # # # # # # # # # #


# if 'companies_loaded' not in st.session_state:
#     st.session_state.companies_loaded = False
#
#
# if not st.session_state.companies_loaded:
#     logging.info('ìµœì´ˆ ì ‘ì†ì´ë¯€ë¡œ íšŒì‚¬ ì •ë³´ ì›¹ë¡œë”© ì‹œì‘...')
#
#     req = requests.Session()
#     response = req.get('https://istheservicedown.com/companies',
#                        headers={'User-Agent': 'Popular browser\'s user-agent'})
#
#     soup = BeautifulSoup(response.content, 'html.parser')
#
#     companies_html_list = soup.find_all('a', class_='b-lazy-bg')
#     companies_list = []
#
#     for company in companies_html_list:
#         code = company['href'].split('/')[-1]
#         name = company.h3.text
#         code_name = code + '/' + name
#         logging.debug(code_name)
#         companies_list.append(code_name)
#
#     logging.info('Total companies count:' + str(len(companies_list)))
#
#     # íŒŒì¼ ì €ì¥
#     with open(config.COMPANIES_LIST_FILE, 'wb') as f_:
#         pickle.dump(companies_list, f_)
#         logging.info('íšŒì‚¬ ëª©ë¡ íŒŒì¼ ì €ì¥ ì™„ë£Œ')
#
#     st.session_state.companies_loaded = True
#
# else:
#     logging.info('íšŒì‚¬ ì •ë³´ ì›¹ë¡œë”© ìŠ¤í‚µ!')


# # # # # # # # # # # # # # # # # # # #
# í˜ì´ì§€ êµ¬ì„±
# # # # # # # # # # # # # # # # # # # #


pg = st.navigation([
    st.Page(config.DASHBOARD_PAGE, title='Dashboard', icon="ğŸš¥", default=True),
    st.Page(config.NEWSBOT_PAGE, title="News Tracker", icon='ğŸ’¬', url_path='news_tracker'),
])

pg.run()
