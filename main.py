import streamlit as st
import logging
import requests
from bs4 import BeautifulSoup
import pickle
import config


# # # # # # # # # # # # # # # # # # # #
# íšŒì‚¬ ëª©ë¡ ë°›ì•„ì˜¤ê¸° (ìµœì´ˆ ì‹¤í–‰ì‹œ 1íšŒ)
# # # # # # # # # # # # # # # # # # # #


if 'companies_loaded' not in st.session_state:
    st.session_state.companies_loaded = False


if not st.session_state.companies_loaded:
    logging.info('ìµœì´ˆ ì ‘ì†ì´ë¯€ë¡œ íšŒì‚¬ ì •ë³´ ì›¹ë¡œë”© ì‹œì‘...')

    req = requests.Session()
    response = req.get('https://istheservicedown.com/companies',
                       headers={'User-Agent': 'Popular browser\'s user-agent'})

    soup = BeautifulSoup(response.content, 'html.parser')

    companies_html_list = soup.find_all('a', class_='b-lazy-bg')
    companies_list = []

    for company in companies_html_list:
        code = company['href'].split('/')[-1]
        name = company.h3.text
        code_name = code + '/' + name
        logging.debug(code_name)
        companies_list.append(code_name)

    logging.info('Total companies count:' + str(len(companies_list)))

    # íŒŒì¼ ì €ì¥
    with open(config.COMPANIES_LIST_FILE, 'wb') as f_:
        pickle.dump(companies_list, f_)
        logging.info('íšŒì‚¬ ëª©ë¡ íŒŒì¼ ì €ì¥ ì™„ë£Œ')

    st.session_state.companies_loaded = True

else:
    logging.info('íšŒì‚¬ ì •ë³´ ì›¹ë¡œë”© ìŠ¤í‚µ!')


# # # # # # # # # # # # # # # # # # # #
# í˜ì´ì§€ êµ¬ì„±
# # # # # # # # # # # # # # # # # # # #


pg = st.navigation([
    st.Page('dashboard.py', title='Dashboard', icon="ğŸš¥", default=True),
    st.Page('news_bot.py', title="News Tracker", icon='ğŸ’¬', url_path='news_tracker'),
])

pg.run()

# st.sidebar.caption('<a href="http://www.istheservicedown.com">ğŸŒ IsTheServiceDown?</a>', unsafe_allow_html=True)

